import torch
import numpy as np
from config import CAP_LEN, CHARACTERS
from torchvision import transforms


def log_train(epoch, trained_sample, total_sample, loss, correct, batch_size):
    '''
    A helper function to log the train result
    '''
    log = 'Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}, Accuracy: {}/{} ({:.0f}%)'.format(
        epoch,
        trained_sample,
        total_sample,
        100. * trained_sample / total_sample,
        loss,
        correct,
        batch_size,
        100. * correct / batch_size
    )
    print(log)


def log_test(loss, correct, test_size):
    '''
    A helper function to log the test result
    '''
    log = 'Test set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)'.format(
        loss, correct, test_size, 100. * correct / test_size)
    print(log)


def train(log_interval, model, device, train_loader, 
          optimizer, epoch, target_transform, 
          folder, model_file_path, criterion=None,
          train_history=None):
    # set model to train mode
    model.train()
    for batch_idx, (data, target) in enumerate(train_loader):
        target = target_transform(target, folder)
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)

        # Set to BCEWithLogitsLoss it criterion is not provided
        if criterion is None:
            criterion = torch.nn.BCEWithLogitsLoss()
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        preds = get_preds_from_output(output)
        true_val = get_preds_from_output(target)

        correct = (preds == true_val).sum()

        if train_history is not None:
            train_history.accmulate_train_history(loss.item(), correct, len(data))
        
        if batch_idx % log_interval == 0:
            log_train(epoch, batch_idx * len(data),
                      len(train_loader.dataset), loss.item(), correct, len(data))
        
            torch.save(model.state_dict(), model_file_path)


def test(model, device, test_loader, target_transform,
         folder, criterion=None, train_history=None):
    # set model to eval mode
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for batch_idx, (data, target) in enumerate(test_loader):
            o_target = target
            target = target_transform(target, folder)
            data, target = data.to(device), target.to(device)
            output = model(data)

            # Set to BCEWithLogitsLoss it criterion is not provided
            if criterion is None:
                criterion = torch.nn.BCEWithLogitsLoss()
            test_loss = criterion(output, target).item()
            preds = get_preds_from_output(output)
            true_val = get_preds_from_output(target)
            correct = (preds == true_val).sum()
            if train_history is not None:
                train_history.accmulate_test_history(
                    test_loss, correct, len(data))
            log_test(test_loss, correct, len(data))


def get_target_from_indices(idxes, folder):
    '''
    Transform the indices, which are generated by the ImageFolder object by defualt
    to torch tensor of shape (batch size, number of unique characters * length of captcha)
    For example, if the length of captcha is 2 and the captcha only consists of digits(0-9),
    the captcha target "82" will be transformed to
        [
            0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 
            0, 0, 1, 0, 0, 0, 0, 0, 0, 0
        ]

    Args:
        idxes (torch.tensor): a tensor with indexes corresponding
            to each folder of the image directory
        folder (ImageFolder): an ImageFolder object that contains information of the classes
    
    Returns:
        torch.tensor: a torch tensor with the multilabel targets encoded
    '''
    characters_length = len(CHARACTERS)
    result_tensor = torch.zeros((len(idxes), characters_length * CAP_LEN))

    def set_kth_tensor(k, c, i):
        position = CHARACTERS.find(c)
        result_tensor[i][characters_length * k + position] = 1

    def set_ith_idx(i, idx):
        cap_str = folder.classes[idx]
        [set_kth_tensor(k, c, i) for k, c in enumerate(cap_str)]

    [set_ith_idx(i, idx) for i, idx in enumerate(idxes)]
    return result_tensor


def get_preds_from_output(output):
    '''
    Get preditions from the output tensor by the model

    Args:
        output (torch.tensor): A torch tensor of size (batch size,
            number of unique characters * length of captcha)

    Returns:
        np.arrays: A numpy array of length equal to batch size, with
            each element equal to the corresponding prediction in string

    '''
    characters_length = len(CHARACTERS)
    preds = [""] * len(output)
    for i in range(CAP_LEN):
        idx_arr = output[:, i *
                         characters_length:(i+1) * characters_length].argmax(dim=1)
        for k, pred in enumerate(idx_arr):
            preds[k] += CHARACTERS[pred.item()]
    return np.array(preds)


def get_transformation(img_width=None, img_height=None):
    '''
    A function to perform a sequence of transformations to the input image
    
    Args:
        img_width (int): desired image width after resize
        img_height (int): desired image height after resize

    Returns:
        torchvision.transforms.Compose
    '''
    transform_list = [] if img_width is None else [
        transforms.Resize((img_height, img_width))]
    transform_list.extend([transforms.ToTensor(),
                           transforms.Normalize((0.8760, 0.8800, 0.8783),
                                                (0.1692, 0.1523, 0.1683))])
    return transforms.Compose(transform_list)
