{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMxZCSN+xRaPP++wzhYXw1R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vNexif/Captcha_AI/blob/main/Captcha_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJfe2vUBUWqQ",
        "outputId": "7d919aa8-62a9-42e2-8302-b87139e0a9ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: astroid in /usr/local/lib/python3.7/dist-packages (2.12.7)\n",
            "Requirement already satisfied: autopep8 in /usr/local/lib/python3.7/dist-packages (1.7.0)\n",
            "Requirement already satisfied: captcha in /usr/local/lib/python3.7/dist-packages (0.4)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (2022.6.15)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (1.15.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.5)\n",
            "Requirement already satisfied: isort in /usr/local/lib/python3.7/dist-packages (5.10.1)\n",
            "Requirement already satisfied: lazy-object-proxy in /usr/local/lib/python3.7/dist-packages (1.7.1)\n",
            "Requirement already satisfied: mccabe in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: mkl-fft in /usr/local/lib/python3.7/dist-packages (1.3.1)\n",
            "Requirement already satisfied: mkl-random in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.7/dist-packages (0.46)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.7/dist-packages (2.9.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (2.21)\n",
            "Requirement already satisfied: pylint in /usr/local/lib/python3.7/dist-packages (2.15.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (2022.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: typed-ast in /usr/local/lib/python3.7/dist-packages (1.5.4)\n",
            "Requirement already satisfied: wincertstore in /usr/local/lib/python3.7/dist-packages (0.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.7/dist-packages (1.14.1)\n",
            "Requirement already satisfied: fastai===1.0.61 in /usr/local/lib/python3.7/dist-packages (1.0.61)\n",
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fastai===1.0.61) (3.2.2)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai===1.0.61) (7.352.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fastai===1.0.61) (2.23.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from fastai===1.0.61) (6.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from fastai===1.0.61) (1.7.3)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai===1.0.61) (1.3.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai===1.0.61) (4.6.3)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai===1.0.61) (2.8.3)\n",
            "Requirement already satisfied: fastprogress>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from fastai===1.0.61) (1.0.3)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.7/dist-packages (from fastai===1.0.61) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fastai===1.0.61) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (1.9.2)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (0.6.2)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (0.4.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (1.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (1.0.3)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (3.3.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (3.0.10)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (3.0.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (57.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (4.64.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (2.11.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (8.1.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->fastai===1.0.61) (2.4.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy>=2.0.18->fastai===1.0.61) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->fastai===1.0.61) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=2.0.18->fastai===1.0.61) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fastai===1.0.61) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fastai===1.0.61) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fastai===1.0.61) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy>=2.0.18->fastai===1.0.61) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy>=2.0.18->fastai===1.0.61) (7.1.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from autopep8) (0.10.2)\n",
            "Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (from mkl-fft) (2019.0)\n",
            "Requirement already satisfied: dpcpp_cpp_rt in /usr/local/lib/python3.7/dist-packages (from mkl-fft) (2022.1.0)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pylint) (2.5.2)\n",
            "Requirement already satisfied: tomlkit>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from pylint) (0.11.4)\n",
            "Requirement already satisfied: dill>=0.2 in /usr/local/lib/python3.7/dist-packages (from pylint) (0.3.5.1)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from pylint) (2.0.1)\n",
            "Requirement already satisfied: intel-cmplr-lib-rt==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2022.1.0)\n",
            "Requirement already satisfied: intel-opencl-rt==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2022.1.0)\n",
            "Requirement already satisfied: intel-cmplr-lic-rt==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2022.1.0)\n",
            "Requirement already satisfied: intel-openmp==2022.1.0 in /usr/local/lib/python3.7/dist-packages (from dpcpp_cpp_rt->mkl-fft) (2022.1.0)\n",
            "Requirement already satisfied: tbb==2021.* in /usr/local/lib/python3.7/dist-packages (from intel-opencl-rt==2022.1.0->dpcpp_cpp_rt->mkl-fft) (2021.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=2.0.18->fastai===1.0.61) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai===1.0.61) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fastai===1.0.61) (1.4.4)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install astroid\\\n",
        "autopep8\\\n",
        "captcha\\\n",
        "certifi\\\n",
        "cffi\\\n",
        "colorama\\\n",
        "isort\\\n",
        "lazy-object-proxy\\\n",
        "mccabe\\\n",
        "mkl-fft\\\n",
        "mkl-random\\\n",
        "numpy\\\n",
        "olefile\\\n",
        "pandas\\\n",
        "Pillow\\\n",
        "pycodestyle\\\n",
        "pycparser\\\n",
        "pylint\\\n",
        "python-dateutil\\\n",
        "pytz\\\n",
        "six\\\n",
        "torch\\\n",
        "torchvision\\\n",
        "typed-ast\\\n",
        "wincertstore\\\n",
        "wrapt\\\n",
        "fastai===1.0.61"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import fastai libraries\n",
        "import json\n",
        "\n",
        "from os.path import join\n",
        "\n",
        "from fastai.vision import *\n",
        "from fastai.callbacks import *\n",
        "from fastai.callback import *\n",
        "from fastai import *\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from captcha.image import ImageCaptcha\n",
        "from shutil import copyfile\n",
        "\n",
        "\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, transforms\n",
        "\n",
        "from captcha.image import ImageCaptcha\n",
        "from shutil import copyfile\n",
        "from os.path import join\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "XpfvtmxOUaqK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def log_train(epoch, trained_sample, total_sample, loss, correct, batch_size):\n",
        "    '''\n",
        "    A helper function to log the train result\n",
        "    '''\n",
        "    log = 'Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        epoch,\n",
        "        trained_sample,\n",
        "        total_sample,\n",
        "        100. * trained_sample / total_sample,\n",
        "        loss,\n",
        "        correct,\n",
        "        batch_size,\n",
        "        100. * correct / batch_size\n",
        "    )\n",
        "    print(log)\n",
        "\n",
        "\n",
        "def log_test(loss, correct, test_size):\n",
        "    '''\n",
        "    A helper function to log the test result\n",
        "    '''\n",
        "    log = 'Test set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
        "        loss, correct, test_size, 100. * correct / test_size)\n",
        "    print(log)\n",
        "\n",
        "\n",
        "def train(log_interval, model, device, train_loader, \n",
        "          optimizer, epoch, target_transform, \n",
        "          folder, model_file_path, criterion=None,\n",
        "          train_history=None):\n",
        "    # set model to train mode\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        target = target_transform(target, folder)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        # Set to BCEWithLogitsLoss it criterion is not provided\n",
        "        if criterion is None:\n",
        "            criterion = torch.nn.BCEWithLogitsLoss()\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        preds = get_preds_from_output(output)\n",
        "        true_val = get_preds_from_output(target)\n",
        "\n",
        "        correct = (preds == true_val).sum()\n",
        "\n",
        "        if train_history is not None:\n",
        "            train_history.accmulate_train_history(loss.item(), correct, len(data))\n",
        "        \n",
        "        if batch_idx % log_interval == 0:\n",
        "            log_train(epoch, batch_idx * len(data),\n",
        "                      len(train_loader.dataset), loss.item(), correct, len(data))\n",
        "        \n",
        "            torch.save(model.state_dict(), model_file_path)\n",
        "\n",
        "\n",
        "def test(model, device, test_loader, target_transform,\n",
        "         folder, criterion=None, train_history=None):\n",
        "    # set model to eval mode\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "            o_target = target\n",
        "            target = target_transform(target, folder)\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "\n",
        "            # Set to BCEWithLogitsLoss it criterion is not provided\n",
        "            if criterion is None:\n",
        "                criterion = torch.nn.BCEWithLogitsLoss()\n",
        "            test_loss = criterion(output, target).item()\n",
        "            preds = get_preds_from_output(output)\n",
        "            true_val = get_preds_from_output(target)\n",
        "            correct = (preds == true_val).sum()\n",
        "            if train_history is not None:\n",
        "                train_history.accmulate_test_history(\n",
        "                    test_loss, correct, len(data))\n",
        "            log_test(test_loss, correct, len(data))\n",
        "\n",
        "\n",
        "def get_target_from_indices(idxes, folder):\n",
        "    '''\n",
        "    Transform the indices, which are generated by the ImageFolder object by defualt\n",
        "    to torch tensor of shape (batch size, number of unique characters * length of captcha)\n",
        "    For example, if the length of captcha is 2 and the captcha only consists of digits(0-9),\n",
        "    the captcha target \"82\" will be transformed to\n",
        "        [\n",
        "            0, 0, 0, 0, 0, 0, 0, 0, 1, 0, \n",
        "            0, 0, 1, 0, 0, 0, 0, 0, 0, 0\n",
        "        ]\n",
        "\n",
        "    Args:\n",
        "        idxes (torch.tensor): a tensor with indexes corresponding\n",
        "            to each folder of the image directory\n",
        "        folder (ImageFolder): an ImageFolder object that contains information of the classes\n",
        "    \n",
        "    Returns:\n",
        "        torch.tensor: a torch tensor with the multilabel targets encoded\n",
        "    '''\n",
        "    characters_length = len(CHARACTERS)\n",
        "    result_tensor = torch.zeros((len(idxes), characters_length * CAP_LEN))\n",
        "\n",
        "    def set_kth_tensor(k, c, i):\n",
        "        position = CHARACTERS.find(c)\n",
        "        result_tensor[i][characters_length * k + position] = 1\n",
        "\n",
        "    def set_ith_idx(i, idx):\n",
        "        cap_str = folder.classes[idx]\n",
        "        [set_kth_tensor(k, c, i) for k, c in enumerate(cap_str)]\n",
        "\n",
        "    [set_ith_idx(i, idx) for i, idx in enumerate(idxes)]\n",
        "    return result_tensor\n",
        "\n",
        "\n",
        "def get_preds_from_output(output):\n",
        "    '''\n",
        "    Get preditions from the output tensor by the model\n",
        "\n",
        "    Args:\n",
        "        output (torch.tensor): A torch tensor of size (batch size,\n",
        "            number of unique characters * length of captcha)\n",
        "\n",
        "    Returns:\n",
        "        np.arrays: A numpy array of length equal to batch size, with\n",
        "            each element equal to the corresponding prediction in string\n",
        "\n",
        "    '''\n",
        "    characters_length = len(CHARACTERS)\n",
        "    preds = [\"\"] * len(output)\n",
        "    for i in range(CAP_LEN):\n",
        "        idx_arr = output[:, i *\n",
        "                         characters_length:(i+1) * characters_length].argmax(dim=1)\n",
        "        for k, pred in enumerate(idx_arr):\n",
        "            preds[k] += CHARACTERS[pred.item()]\n",
        "    return np.array(preds)\n",
        "\n",
        "\n",
        "def get_transformation(img_width=None, img_height=None):\n",
        "    '''\n",
        "    A function to perform a sequence of transformations to the input image\n",
        "    \n",
        "    Args:\n",
        "        img_width (int): desired image width after resize\n",
        "        img_height (int): desired image height after resize\n",
        "\n",
        "    Returns:\n",
        "        torchvision.transforms.Compose\n",
        "    '''\n",
        "    transform_list = [] if img_width is None else [\n",
        "        transforms.Resize((img_height, img_width))]\n",
        "    transform_list.extend([transforms.ToTensor(),\n",
        "                           transforms.Normalize((0.8760, 0.8800, 0.8783),\n",
        "                                                (0.1692, 0.1523, 0.1683))])\n",
        "    return transforms.Compose(transform_list)\n"
      ],
      "metadata": {
        "id": "jfse2Ahhv8hm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Const for captcha generation\n",
        "from os.path import join\n",
        "DES_PATH = \".\"\n",
        "RESULT_FILE_NAME = 'captcha_img'\n",
        "\n",
        "CHARACTERS = '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "CAP_LEN = 4\n",
        "\n",
        "NO_TRAIN_CAP = 100000\n",
        "NO_TEST_CAP = 10000\n",
        "\n",
        "# Config for model training\n",
        "TRAIN_DIR = join(DES_PATH, RESULT_FILE_NAME)\n",
        "TEST_DIR = join(DES_PATH, RESULT_FILE_NAME)\n",
        "OUT_FILENAME = join(RESULT_FILE_NAME, 'labels.csv')\n",
        "\n",
        "EPOCHS = 2\n",
        "LOG_INTERVAL = 10\n",
        "SEED = 1\n",
        "LR = 1e-3\n",
        "BATCH_SIZE = 128\n"
      ],
      "metadata": {
        "id": "_T6ml_yVrmE4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate 100000 images for the AI to learn on\n",
        "def gen_str(size, characters):\n",
        "    while True:\n",
        "        positions = np.random.randint(len(characters), size=size)\n",
        "        yield ''.join(map(lambda x: characters[x], positions))\n",
        "\n",
        "\n",
        "def generate_captcha(captcha, out_dir, no_of_img=10000, size=CAP_LEN, characters=CHARACTERS):\n",
        "    if not os.path.isdir(out_dir):\n",
        "        os.makedirs(out_dir)\n",
        "\n",
        "    str_gen = gen_str(size, characters)    \n",
        "\n",
        "    img_dict = defaultdict(int)\n",
        "    for i in range(no_of_img):\n",
        "        text = next(str_gen)\n",
        "        if i % 10000 == 0:\n",
        "            print(\"Generating image {} of {}\".format(i, no_of_img))\n",
        "        img_name = f'{text}_{img_dict[text]}.png'\n",
        "        img_dict[text] += 1\n",
        "        captcha.write(text, join(out_dir, img_name))\n",
        "    return True\n",
        "\n",
        "\n",
        "def generate_feather(train_dir, valid_dir, out_filename):\n",
        "    def process_filename(filename):\n",
        "        text = filename.split('_')[0]\n",
        "        return list(map(lambda x: f'{x[1]}{x[0]}', enumerate(text)))\n",
        "\n",
        "\n",
        "    rows = []\n",
        "    for filename in os.listdir(train_dir):\n",
        "        rows.append((os.path.join('train', filename),\n",
        "                    process_filename(filename), False))\n",
        "\n",
        "    for filename in os.listdir(valid_dir):\n",
        "        rows.append((os.path.join('valid', filename),\n",
        "                    process_filename(filename), True))\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=['name', 'label', 'is_valid'])\n",
        "    df.to_feather(out_filename, index=False)\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    ic = ImageCaptcha()\n",
        "\n",
        "    train_dir = join(DES_PATH, RESULT_FILE_NAME, 'train')\n",
        "    valid_dir = join(DES_PATH, RESULT_FILE_NAME, 'valid')\n",
        "\n",
        "    directories = [train_dir, valid_dir]\n",
        "    nos_of_img = [NO_TRAIN_CAP, NO_TEST_CAP]\n",
        "\n",
        "    for directory, no_of_img in zip(directories, nos_of_img):\n",
        "        generate_captcha(captcha=ic, out_dir=directory,\n",
        "                         no_of_img=no_of_img, size=CAP_LEN, characters=CHARACTERS)\n",
        "    \n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "DkpKtkWvUZpS",
        "outputId": "b2b6f055-4ce5-4392-bf10-3583337f4790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating image 0 of 100000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-91191a363eec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-91191a363eec>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_of_img\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnos_of_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         generate_captcha(captcha=ic, out_dir=directory,\n\u001b[0;32m---> 56\u001b[0;31m                          no_of_img=no_of_img, size=CAP_LEN, characters=CHARACTERS)\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-91191a363eec>\u001b[0m in \u001b[0;36mgenerate_captcha\u001b[0;34m(captcha, out_dir, no_of_img, size, characters)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mimg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{text}_{img_dict[text]}.png'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mimg_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mcaptcha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captcha/image.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, chars, output, format)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mfile\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \"\"\"\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captcha/image.py\u001b[0m in \u001b[0;36mgenerate_image\u001b[0;34m(self, chars)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mbackground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m238\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m220\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_captcha_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_noise_dots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_noise_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captcha/image.py\u001b[0m in \u001b[0;36mcreate_captcha_image\u001b[0;34m(self, chars, color, background)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m                 \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_draw_character\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_draw_character\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captcha/image.py\u001b[0m in \u001b[0;36m_draw_character\u001b[0;34m(c)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;31m# rotate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBILINEAR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m             \u001b[0;31m# warp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mrotate\u001b[0;34m(self, angle, resample, expand, center, translate, fillcolor)\u001b[0m\n\u001b[1;32m   2053\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2055\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAFFINE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfillcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, size, method, data, resample, fill, fillcolor)\u001b[0m\n\u001b[1;32m   2355\u001b[0m             return (\n\u001b[1;32m   2356\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2357\u001b[0;31m                 \u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2358\u001b[0m                 \u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGBA\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, size, method, data, resample, fill, fillcolor)\u001b[0m\n\u001b[1;32m   2377\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m             im.__transformer(\n\u001b[0;32m-> 2379\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfillcolor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2380\u001b[0m             )\n\u001b[1;32m   2381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__transformer\u001b[0;34m(self, box, image, method, data, resample, fill)\u001b[0m\n\u001b[1;32m   2453\u001b[0m             \u001b[0mresample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNEAREST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2455\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all the inputs and targets from image files and save it to labels\n",
        "\n",
        "def process_filename(filename):\n",
        "    text = filename.split('_')[0]\n",
        "    return list(map(lambda x: f'{x[1]}{x[0]}', enumerate(text)))\n",
        "\n",
        "path = Path('captcha_img')\n",
        "rows = []\n",
        "for filename in os.listdir(path/'train'):\n",
        "    if not filename.endswith('png'):\n",
        "        continue\n",
        "    rows.append((os.path.join('train', filename), process_filename(filename), False))\n",
        "\n",
        "for filename in os.listdir(path/'valid'):\n",
        "    if not filename.endswith('png'):\n",
        "        continue\n",
        "    rows.append((os.path.join('valid', filename), process_filename(filename), True))\n",
        "    \n",
        "df = pd.DataFrame(rows, columns=['name', 'label', 'is_valid'])\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "j44YOrn5Uatu",
        "outputId": "9e5a6299-d881-4f76-d18c-4766c1817384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-03a753e04aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mrows\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocess_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'captcha_img/valid'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a databunch object for the fastai learner\n",
        "path = Path('captcha_img')\n",
        "il = ImageList.from_df(df, path).split_from_df().label_from_df()\n",
        "data = il.databunch()"
      ],
      "metadata": {
        "id": "IEF86mWDXHQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.show_batch()"
      ],
      "metadata": {
        "id": "HQ8AYwM-bUXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def captcha_accuracy(y_pred, y_true, get_mean=True):\n",
        "    sorted_pred, _ = y_pred.sort(1)\n",
        "    y_pred = y_pred >= sorted_pred[:, -4].float().view((-1, 1))\n",
        "    y_true = y_true.byte()\n",
        "    \n",
        "    result = (((y_pred == y_true) & (y_true == 1)).float().sum(1) / 4.)\n",
        "    if get_mean == True:\n",
        "        result = result.mean()\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "X6-YdwHUbaok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = cnn_learner(data, models.resnet50,metrics=captcha_accuracy, pretrained=False)"
      ],
      "metadata": {
        "id": "ONqasYloc7kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot(skip_end=5)"
      ],
      "metadata": {
        "id": "l1y76_sXbgaX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit_one_cycle(2, max_lr=slice(3e-3,2e-2))"
      ],
      "metadata": {
        "id": "2zhVYNkrdGtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.save('res-default')"
      ],
      "metadata": {
        "id": "_uTq2i5ODabk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_preds_with_top_loss_idx(learn):\n",
        "    y_pred, y_true, losses = learn.get_preds(with_loss=True)\n",
        "    acc = captcha_accuracy(y_pred, y_true, get_mean=False)\n",
        "    sorted_pred, _ = y_pred.sort(1)\n",
        "    losses = losses.view((-1, 144)).mean(1)    \n",
        "    top_loss_idx = losses.argsort(descending=True)\n",
        "    \n",
        "    y_pred = y_pred >= sorted_pred[:, -4].float().view((-1, 1))\n",
        "    return y_pred, y_true, losses, top_loss_idx, acc\n",
        "\n",
        "def show_top_losses(learn, row=3):\n",
        "    y_pred, y_true, losses, top_loss_idx, acc = get_preds_with_top_loss_idx(learn)\n",
        "    axs = subplots(row, row, figsize=(20, 10), title='index / pred / true / loss / accuracy').reshape(-1)\n",
        "    y_recon = data.valid_ds.y.reconstruct\n",
        "    for idx, ax in zip(top_loss_idx[:row*row], axs):\n",
        "        title = f\"{idx} / {y_recon(y_pred[idx])} / {y_recon(y_true[idx])} / {losses[idx]:0.3f} / {acc[idx]:0.2f}\"\n",
        "        ax = show_image(data.valid_ds[idx][0], ax=ax)\n",
        "        ax.set_title(title)"
      ],
      "metadata": {
        "id": "U8U6qaDQDqJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_top_losses(learn)"
      ],
      "metadata": {
        "id": "wui0xmEWDsJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn2 = cnn_learner(data, models.resnet50,metrics=captcha_accuracy, pretrained=False, wd=0.05, ps=0.2)"
      ],
      "metadata": {
        "id": "iY1zacsfDvgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn2.fit_one_cycle(2, max_lr=slice(3e-3,2e-2))"
      ],
      "metadata": {
        "id": "L6Rxh4a5DyCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn2.save('res-0.05-0.2')"
      ],
      "metadata": {
        "id": "wCiFFBSoDzy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_top_losses(learn2)"
      ],
      "metadata": {
        "id": "NSVrZAY1D2la"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn3 = cnn_learner(data, models.resnet50,metrics=captcha_accuracy, pretrained=False, wd=0.02, ps=0.2)\n",
        "learn3.fit_one_cycle(2, max_lr=slice(3e-3,2e-2))"
      ],
      "metadata": {
        "id": "JnFOCMmdD4cR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn3.save('res-0.02-0.2')"
      ],
      "metadata": {
        "id": "qfdOIYF-D7Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_top_losses(learn3)"
      ],
      "metadata": {
        "id": "jFevWlxBD85z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn4 = cnn_learner(data, models.resnet50,metrics=captcha_accuracy, pretrained=False, wd=0.01, ps=0.2)\n",
        "learn4.fit_one_cycle(2, max_lr=slice(3e-3,2e-2))"
      ],
      "metadata": {
        "id": "b-5ijl7kD-CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn4.save('res-0.01-0.2')"
      ],
      "metadata": {
        "id": "qjJiHJWVEBqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn5 = cnn_learner(data, models.resnet50,metrics=captcha_accuracy, pretrained=False, wd=0.01, ps=0.1)\n",
        "learn5.fit_one_cycle(2, max_lr=slice(3e-3,2e-2))"
      ],
      "metadata": {
        "id": "xcf8cFKxEEJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_top_losses(learn5)"
      ],
      "metadata": {
        "id": "J8H02yXXEFYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn5.save('res-0.01-0.1')"
      ],
      "metadata": {
        "id": "amWQNjDfEGny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn2.lr_find()"
      ],
      "metadata": {
        "id": "9l8eAYjSEGhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn2.recorder.plot(skip_end=10)"
      ],
      "metadata": {
        "id": "_6Okbru9EGfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn2.fit_one_cycle(1, max_lr=slice(1e-6,5e-5))"
      ],
      "metadata": {
        "id": "hB1GhFKyEKGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_top_losses(learn2)"
      ],
      "metadata": {
        "id": "jkaZ4ZQNEMSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn2.save('res-0.05-0.2-stage2')"
      ],
      "metadata": {
        "id": "KcvJmWZcENnA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn2 = learn2.load('res-0.05-0.2-stage2')"
      ],
      "metadata": {
        "id": "UQhg3sgMEPMq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hooked_backward(learn, xb, layer_idx):\n",
        "    m = learn.model.eval()\n",
        "    with hook_output(m[0][layer_idx]) as hook_a:\n",
        "            preds = m(xb)\n",
        "    return hook_a\n",
        "\n",
        "\n",
        "def show_heatmap(hm, x_im, item_idx, layer_idx, ax):\n",
        "    x_im.show(ax, title=f'layer {layer_idx}, item {item_idx}')\n",
        "    ax.imshow(hm, alpha=0.6, extent=(0,160, 60,0),\n",
        "              interpolation='bilinear', cmap='magma');\n",
        "\n",
        "def visualize_layer_of_item(learn, item_idxes, layer_idxes, row=2):\n",
        "    data = learn.data\n",
        "    axes = subplots(row, row, figsize=(20, 10)).reshape(-1)\n",
        "    for item_idx, layer_idx, ax in zip(item_idxes, layer_idxes, axes):\n",
        "        x,y = data.valid_ds[item_idx]\n",
        "        xb, _ = data.one_item(x)\n",
        "\n",
        "        hook_a = hooked_backward(learn, xb.cuda(), layer_idx)\n",
        "        acts  = hook_a.stored[0].cpu()\n",
        "        avg_acts = acts.mean(0)\n",
        "\n",
        "        show_heatmap(avg_acts, x, item_idx, layer_idx, ax)"
      ],
      "metadata": {
        "id": "-e9dYfwJEPHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_layer_of_item(learn2, [9000, 9001, 9000, 9000], [5, 5, 6, 7])"
      ],
      "metadata": {
        "id": "yQVPXfIuEVLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_layer_of_item(learn3, [9000, 9001, 9000, 9000], [5, 5, 6, 7])"
      ],
      "metadata": {
        "id": "Vg84o9WArE-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_layer_of_item(learn4, [9000, 9001, 9000, 9000], [5, 5, 6, 7])"
      ],
      "metadata": {
        "id": "yrQmd_AarE3L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}